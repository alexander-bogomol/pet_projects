 В данной работе отражена попытка классификации новостей. Датасет довольно "грязный" и разбалансированный.
 В результате были получены довольно скромные скоры на всех моделях. ROC curve не показала каких-то
 возможностей для оптимизации threshold. Наибольший f1-score показала модель логистической регрессии с учётом
 разбалансировки классов (class_weight='balanced'). Fasttext выдал неплохие цифры с помощью автоматической
 оценки, но при проверке "руками", даже на глаз стало понятно, что они отличаются от реальности.
 
 Для улучшения результатов нужно лучше очистить данные, лемматизировать их, выбросить весь мусор и
 нормализовать символы. Кроме того, можно обучать на данных сбалансированных по классам (за счёт уменьшения
 присутствия доминирующего класса). Также можно попробовать применить какие-то модели на нейронных сетях
 (если возникнут проблемы с недостатком данных, можно будет попробовать аугментацию).
