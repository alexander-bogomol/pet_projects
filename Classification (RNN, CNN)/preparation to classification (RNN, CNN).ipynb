{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5635189-8edc-46de-9986-13e39b0a764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b5df3e-ed6f-4114-b5ac-0bea5abeafd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01740717887878418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading builder script",
       "rate": null,
       "total": 4063,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80dff5136954b5ca05bd2e99cffea1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01184844970703125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading metadata",
       "rate": null,
       "total": 2653,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db112ae61df5464bb2b10d75e59491c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ag_news/default (download: 29.88 MiB, generated: 30.23 MiB, post-processed: Unknown size, total: 60.10 MiB) to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011792898178100586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading data",
       "rate": null,
       "total": 11045148,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e3b9aedfd34a1a860c616ee3ad488e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012177705764770508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading data",
       "rate": null,
       "total": 751209,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84b454a991847ceaa3870c326f8494e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/751k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011949539184570312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating train split",
       "rate": null,
       "total": 120000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011278867721557617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating test split",
       "rate": null,
       "total": 7600,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ag_news downloaded and prepared to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011137247085571289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957b1826c86d44b5816b9c0e8d213493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 120000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"ag_news\")\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b170b3c-e079-4a51-8c4e-facaab60c21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b034bf5-2ee0-43d6-964b-c45e773cc2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(api.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1244eca-5eba-4728-8f27-c6b44bdec274",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 11.7% 23.4/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 35.4% 70.6/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================---------------------] 59.6% 118.9/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 83.2% 166.1/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0958751f-370d-4b6d-bbed-aad28d8a0592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.093819, -0.38502 , -0.08292 , -0.55912 , -1.0564  ,  0.21713 ,\n",
       "        0.25867 , -0.25095 ,  0.58058 , -0.53596 ,  0.027442, -0.49675 ,\n",
       "       -2.3067  ,  0.26241 ,  0.94936 , -0.22972 ,  0.43156 ,  0.30985 ,\n",
       "        0.837   ,  0.25471 ,  0.97212 , -0.4653  , -0.37191 , -1.1439  ,\n",
       "        0.22666 , -0.59356 , -0.48548 ,  0.080302,  0.11148 , -0.21289 ,\n",
       "        0.52485 ,  0.14826 ,  0.21012 , -0.42637 ,  0.21639 , -0.35195 ,\n",
       "       -0.0693  ,  0.76786 , -0.057718,  0.33779 , -0.27207 , -0.54431 ,\n",
       "       -0.041565,  0.17028 , -0.035933,  1.007   , -0.34321 ,  0.21722 ,\n",
       "       -0.32818 ,  1.644   ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec['alaska']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a0fb350-f501-4d25-9205-b027412c337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011878252029418945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 120000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eba57527d6246cf930de1b08bba43cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011279821395874023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7600,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40755a18a3154850975a9c89733fc955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH=128\n",
    "\n",
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda item: {\n",
    "        \"tokenized\": tokenizer.tokenize(item[\"text\"])[:MAX_LENGTH]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089499cc-0ad6-4982-b183-801484a1ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(word2vec.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230e3a0f-acf7-4f68-bf9e-907e563733e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word):\n",
    "    if word in word2idx.keys():\n",
    "        return word2idx[word]\n",
    "    return word2idx[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4cbbd49-b9f5-4e6b-8f32-298eba5cc206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011874675750732422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 120000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0b9069191d42c997696f443b158cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01212000846862793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7600,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dde2f5f27ba4f508650896fa39e642c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda item: {\n",
    "        \"features\": [encode(word) for word in item[\"tokenized\"]]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab074c05-836b-407b-8076-f7108fcbeef5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'label': 2,\n",
       " 'tokenized': ['Wall',\n",
       "  'St',\n",
       "  '.',\n",
       "  'Bears',\n",
       "  'Claw',\n",
       "  'Back',\n",
       "  'Into',\n",
       "  'the',\n",
       "  'Black',\n",
       "  '(',\n",
       "  'Reuters',\n",
       "  ')',\n",
       "  'Reuters',\n",
       "  '-',\n",
       "  'Short',\n",
       "  '-',\n",
       "  'sellers',\n",
       "  ',',\n",
       "  'Wall',\n",
       "  'Street',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'dwindling',\n",
       "  '\\\\',\n",
       "  'band',\n",
       "  'of',\n",
       "  'ultra',\n",
       "  '-',\n",
       "  'cynics',\n",
       "  ',',\n",
       "  'are',\n",
       "  'seeing',\n",
       "  'green',\n",
       "  'again',\n",
       "  '.'],\n",
       " 'features': [62980,\n",
       "  62980,\n",
       "  1,\n",
       "  62980,\n",
       "  62980,\n",
       "  62980,\n",
       "  62980,\n",
       "  13,\n",
       "  62980,\n",
       "  17,\n",
       "  62980,\n",
       "  20,\n",
       "  62980,\n",
       "  28,\n",
       "  62980,\n",
       "  28,\n",
       "  49286,\n",
       "  4,\n",
       "  62980,\n",
       "  62980,\n",
       "  48,\n",
       "  137,\n",
       "  214902,\n",
       "  370,\n",
       "  1645,\n",
       "  39,\n",
       "  8606,\n",
       "  28,\n",
       "  380053,\n",
       "  4,\n",
       "  70,\n",
       "  1321,\n",
       "  1745,\n",
       "  389,\n",
       "  1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07bc5a65-ca21-4c9e-83f5-ef7991110aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"text\", \"tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2913a876-3357-453f-8f32-33e47ca2b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    max_len = max(len(row[\"features\"]) for row in batch) #get max lenght\n",
    "    input_embeds = torch.empty((len(batch), max_len), dtype=torch.long)\n",
    "    labels = torch.empty(len(batch), dtype=torch.long)\n",
    "    for idx, row in enumerate(batch):\n",
    "        to_pad = max_len - len(row[\"features\"])\n",
    "        input_embeds[idx] = torch.cat((row[\"features\"], torch.zeros(to_pad)))\n",
    "        labels[idx] = row[\"label\"]\n",
    "    return {\"features\": input_embeds, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddd4dac4-f6af-4dfa-beaf-b397271622b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fdffb0b-8037-4ca5-84a5-e964b1b99bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    k: DataLoader(\n",
    "        ds, shuffle=(k==\"train\"), batch_size=64, collate_fn=collate_fn\n",
    "    ) for k, ds in dataset.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35697bbc-aeaf-4987-ac21-ef156251a2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].unique('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74aeea8a-c0ba-4d07-b8b2-67527d526d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embedding_dim=embed_size)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.cl = nn.Sequential(\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)  # (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn(x)\n",
    "        prediction = self.cl(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb253c73-c623-4144-8339-3ef28acbfe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = CNNModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd325704-2e5e-4dd6-86d1-417408ed4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.model.embeddings.weight[idx] = torch.tensor(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b02dbafe-7153-4ef6-b3dc-937d72c32841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "def training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2):\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders['train'], leave=False)\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch['features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d348b18-3a8d-4802-a3d1-8d896bce30f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (embeddings): Embedding(1193514, 50)\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv1d(50, 50, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(50, 50, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv1d(50, 50, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (7): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): AdaptiveMaxPool1d(output_size=1)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (cl): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d87e7ce6-5c6b-41b9-9512-b13321c08550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01210474967956543,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01074671745300293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1875,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.3699994385242462, accuracy: 0.8731578588485718\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011649847030639648,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1875,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.35893747210502625, accuracy: 0.8739473223686218\n"
     ]
    }
   ],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9855255-cfac-491d-a5e7-73165fd883e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.w_x = nn.Parameter(torch.randn(embedding_size, hidden_size))\n",
    "        self.w_h = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.b_x = nn.Parameter(torch.randn(1, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.randn(1, hidden_size))\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
    "        seq_len = x.size(1)\n",
    "        for idx in range(seq_len):\n",
    "            hidden = torch.tanh(\n",
    "                x[:, idx] @ self.w_x + self.b_x + hidden @ self.w_h + self.b_h\n",
    "            )\n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d4492b2-cca3-4dcd-880d-fb17a7c23a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.rnn = RNN(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        hidden = self.rnn(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd87a3f7-d371-40ff-92f8-e23d0566fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "rnn_model = RNNModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17fc30c3-b921-465e-893a-67839ba20f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011137962341308594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010684013366699219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1875,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 1.4551663398742676, accuracy: 0.2567105293273926\n"
     ]
    }
   ],
   "source": [
    "training(rnn_model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "421f288b-d3aa-46ca-9fd3-095d2639a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchRNNModel(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(len(word2idx), embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, batch_first=True)\n",
    "        self.clf = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        hidden = self.rnn(x)\n",
    "        output = self.clf(hidden[1].squeeze(0))\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c02dcdf5-7a1e-4d43-9b90-7591b19e5460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011211633682250977,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010900020599365234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1875,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 1.4159088134765625, accuracy: 0.2505263090133667\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch_rnn_model = TorchRNNModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "training(torch_rnn_model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57a173cb-5062-4c30-9cb4-5da2a119ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = nn.RNN(10, 20, batch_first=True)\n",
    "input = torch.randn(5, 10)\n",
    "#h0 = torch.randn(2, 3, 20)\n",
    "output, hn = r(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "974c5c20-9d1a-4954-b1e0-5cfc2b51c1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 20]), torch.Size([1, 20]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f020061-3dd3-4aa1-8fd4-5a54f7cd96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.w_rh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_rh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_rx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_rx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "        self.w_zh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_zh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_zx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_zx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "        self.w_nh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_nh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_nx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_nx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden = None):\n",
    "        '''\n",
    "        x – torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
    "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
    "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
    "        '''\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "        \n",
    "        for cur_idx in range(x.size(1)):\n",
    "            r = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_rx + self.b_rx + hidden @ self.w_rh + self.b_rh\n",
    "            )\n",
    "            z = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_zx + self.b_zx + hidden @ self.w_zh + self.b_zh\n",
    "            )\n",
    "            n = torch.tanh(\n",
    "                x[:, cur_idx] @ self.w_nx + self.b_nx + r * (hidden @ self.w_nh + self.b_nh)\n",
    "            )\n",
    "            hidden = (1 - z) * n + z * hidden\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09296a4f-5bb8-4f29-acb1-805ac1c0e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.gru = GRU(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        hidden = self.gru(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c538933-0afa-4314-8817-6ee5749ac05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru_model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c610f990-a663-49e3-b495-d779634de6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012999773025512695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011408329010009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1875,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.5521388053894043, accuracy: 0.8010525703430176\n"
     ]
    }
   ],
   "source": [
    "training(gru_model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e0f8fbb-ddd7-4be8-90ed-5eeb97832161",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gru_emb_model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru_emb_model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00f15558-6661-46d3-8ba3-a2fc9e856701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7579e+00, -7.3016e-01,  1.5156e+00,  8.3016e-03, -1.2871e+00,\n",
       "        -6.6036e-01,  1.5145e-04, -1.2049e-01, -1.6718e+00,  5.7664e-01,\n",
       "        -1.1666e-01,  1.8611e-01, -7.8184e-01, -1.1965e+00,  4.3965e-01,\n",
       "         6.9593e-01, -2.0213e-02,  1.5535e-01, -3.3549e-01, -6.3869e-02,\n",
       "         4.8957e-01,  1.3508e+00, -1.2582e+00, -2.3653e+00,  1.1004e-01,\n",
       "        -2.0959e-01, -9.0654e-01, -6.9989e-01, -1.2343e+00, -1.5817e-01,\n",
       "        -1.5985e+00,  1.3898e+00, -9.9889e-01,  2.4111e-01,  3.1420e-01,\n",
       "         3.1689e-01,  1.1221e+00,  1.2584e+00, -1.2355e-02, -9.3369e-01,\n",
       "         1.3225e+00,  1.5377e+00, -7.3059e-01,  1.1931e-01, -2.4281e+00,\n",
       "        -4.5330e-01,  1.8753e+00,  2.0441e+00, -1.1219e+00,  1.7999e-01],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_emb_model.embed.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe6acd73-31c4-4a13-8dee-98b28b01ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            gru_emb_model.embed.weight[idx] = torch.tensor(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "651f676b-f8cd-425e-8281-d6d82d92016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7870,  0.7215,  0.2915, -0.0565,  0.3168,  0.4717,  0.0235,  0.6957,\n",
       "         0.2078,  0.6098, -0.2239,  0.7481, -2.6208,  0.2012, -0.4810,  0.1290,\n",
       "         0.0352, -0.2449, -0.3609,  0.0267,  0.2898, -0.1070, -0.3462,  0.0211,\n",
       "         0.5451, -1.0958, -0.2740,  0.2233,  1.0827, -0.0290, -0.8403,  0.5862,\n",
       "        -0.3651,  0.3402,  0.8961,  0.3276,  0.2427,  0.6840, -0.3437,  0.1358,\n",
       "        -2.2162, -0.4254,  0.4616,  0.8863, -0.2201,  0.0256, -0.3862,  0.0801,\n",
       "        -0.0753, -0.6146], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_emb_model.embed.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303bca96-a452-4796-91bf-c172ef183413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011551380157470703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01107025146484375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1875,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.47915175557136536, accuracy: 0.8349999785423279\n"
     ]
    }
   ],
   "source": [
    "training(gru_emb_model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ad1cd-7d95-4247-ab7f-29b8b8a03428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_embeddings(model, req_grad=False):\n",
    "    embeddings = model.embed\n",
    "    for c_p in embeddings.parameters():\n",
    "        c_p.requires_grad = req_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23b546-73a7-40f9-bb60-c952929f6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2, num_freeze_iter=1000):\n",
    "    freeze_embeddings(model)\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
    "        for batch in pbar:\n",
    "            if num_iter > num_freeze_iter and e < 1:\n",
    "                freeze_embeddings(model, True)\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be7282-b521-4c86-8f10-fede75c90b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gru_emb_model_1 = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru_emb_model_1.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a26d7-4801-4158-9595-c636e6852014",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            gru_emb_model_1.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad98854c-e1fd-4bce-a387-1bf3a706b969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011415243148803711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012496232986450195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1875,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.4601065516471863, accuracy: 0.8417105078697205\n"
     ]
    }
   ],
   "source": [
    "training_freeze(gru_emb_model_1, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c24a1-0065-45b3-92f6-5ffb01388be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
